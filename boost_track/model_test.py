import torch
import numpy as np
import torchvision.transforms as T
from tracker.embedding import ModelFactory, ModelConfigFactory

WEIGHTS_DIR = "external/weights"

WEIGHTS = {
    'swinv2': f'{WEIGHTS_DIR}/Micrsorft_swinv2_large_patch4_window12_192_22k.pth',
    'convNext': f'{WEIGHTS_DIR}/convnext_xlarge_22k_1k_384_ema.pth',
    'La_Transformer': f'{WEIGHTS_DIR}/LaTransformer.pth',
    'VIT': f'{WEIGHTS_DIR}/vit_base_ics_cfs_lup.pth',
    'dinov2': f'{WEIGHTS_DIR}/dinov2_vitb14_pretrain.pth',
    'DETR': f'{WEIGHTS_DIR}/r50_deformable_detr.pth',
}

def test_model_preprocessing_and_output(model_type):
    """
    ëª¨ë¸ë³„ ì…ë ¥ ì „ì²˜ë¦¬ ë° ì¶œë ¥ê°’ í˜•íƒœë¥¼ ìë™ìœ¼ë¡œ í™•ì¸í•˜ëŠ” í…ŒìŠ¤íŠ¸ í•¨ìˆ˜

    :param model_name: í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ ì´ë¦„ (ex: 'dinov2', 'CLIP', 'swinv2', ...)
    """
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # ëª¨ë¸ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
    config = ModelConfigFactory.create_config(model_type)
    config.reid_model_path = WEIGHTS[model_type]  # ê°€ì¤‘ì¹˜ ê²½ë¡œ ì¶”ê°€

    print(f"ğŸ” ëª¨ë¸ëª…: {config.model_type}, ê°€ì¤‘ì¹˜ ê²½ë¡œ: {config.reid_model_path}")  # ë””ë²„ê¹…ìš© ì¶œë ¥

    model = ModelFactory.create_model(config, device)
    # ëª¨ë¸ ìƒì„±
    try:
        model = ModelFactory.create_model(config, device)
        model.eval()
    except Exception as e:
        print(f"[ERROR] ëª¨ë¸ {model_name} ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    print(f"\nğŸš€ í…ŒìŠ¤íŠ¸ ëª¨ë¸: {model_name}")
    print(f"ğŸ“Œ ëª¨ë¸ ì…ë ¥ í¬ê¸°: {config.crop_size}")

    # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„± (ê¸°ë³¸ì ìœ¼ë¡œ í°ìƒ‰ ì´ë¯¸ì§€)
    dummy_image = np.ones((config.crop_size[1], config.crop_size[0], 3), dtype=np.uint8) * 255
    
    # ì „ì²˜ë¦¬ ìˆ˜í–‰
    transform = config.get_transform()
    try:
        preprocessed_tensor = transform(dummy_image).unsqueeze(0).to(device)
        print(f"âœ… ì „ì²˜ë¦¬ ì„±ê³µ! ì…ë ¥ Tensor í˜•íƒœ: {preprocessed_tensor.shape}")
    except Exception as e:
        print(f"[ERROR] ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return

    # ëª¨ë¸ ì‹¤í–‰ ë° ì¶œë ¥ê°’ í™•ì¸
    try:
        with torch.no_grad():
            output = model(preprocessed_tensor)
        
        if isinstance(output, dict):
            for key, value in output.items():
                if isinstance(value, torch.Tensor):  # ğŸ” ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ shape ì¶œë ¥
                    print(f"ğŸ” ì¶œë ¥ Key: {key}, Shape: {value.shape}")
                else:
                    print(f"âš ï¸ ì¶œë ¥ Key: {key} ëŠ” ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ë‹¤ë¥¸ í˜•ì‹: {(value)}")
        elif isinstance(output, torch.Tensor):
            print(f"âœ… ëª¨ë¸ ì¶œë ¥ Tensor í˜•íƒœ: {output.shape}")
        else:
            print(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì¶œë ¥ íƒ€ì…: {type(output)}")

    except Exception as e:
        print(f"[ERROR] ëª¨ë¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")

# í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ ëª©ë¡
model_list = ["DETR"]

# ëª¨ë“  ëª¨ë¸ì— ëŒ€í•´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
for model_name in model_list:
    test_model_preprocessing_and_output(model_name)
